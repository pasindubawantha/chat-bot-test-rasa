{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FllyYWZrY8f0"
   },
   "source": [
    "## Building Your Own Chatbot: The Hard Way Made Easy \n",
    "\n",
    "\n",
    "---\n",
    "<img src=\"https://miro.medium.com/max/800/1*CKjk4H7XnYghNmau6wGU9g.jpeg\" alt=\"Drawing\" width=\"45%\"/>\n",
    "\n",
    "\n",
    "In this workshop, you will learn how to build your own conversational AI assistant using machine learning and real conversational data. The goal of this workshop is to walk you through the process of building an ML-powered assistant from scratch and build an actual assistant which you can improve later.\n",
    "\n",
    "\n",
    "There are no additional requirements to run this notebook. But if you encounter any issues or have more questions about the content included here, feel free to send a message to following email address at gamagebimsara@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7D42AfuY8f4"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AYKRcpKY8f8"
   },
   "source": [
    "During the course of this 3-hour workshop, you will go through each stage of the chatbot development and build an assistant capable of providing real-time weather information of a given location. Below is an example conversation your assistant will be able to handle:\n",
    "\n",
    "U: Hello  \n",
    "A: Hey, how can I help?  \n",
    "U: What's the weather outside?  \n",
    "A: Where are you based?  \n",
    "U: Tell me the current weather in Colombo.  \n",
    "A: Sure, it is currently rainy in Colombo.   \n",
    "U: Goodbye.\n",
    "\n",
    "A: Goodbye :(\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymUGMEcRY8f_"
   },
   "source": [
    "The workshop consists of the following stages:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**0. Intro:**  \n",
    "\n",
    "   0.1 Setup and installation \n",
    "      \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**1. Stage 1: Natural language understanding:** \n",
    "\n",
    "   1.1. Designing the happy path  \n",
    "    1.2. Generating the NLU training examples  \n",
    "    1.3. Designing the training pipeline  \n",
    "    \n",
    "      \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**2. Stage 2: Dialogue management model:** \n",
    "    \n",
    " 2.1. Designing training stories  \n",
    "    2.2. Creating a custom action  \n",
    "    2.3. Defining the domain  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "      \n",
    "**3. Stage 3: Training and testing the model:**  \n",
    "   \n",
    "  3.1. Training the bot   \n",
    "    3.2. Testing the bot in the terminal  \n",
    "    3.3. Model evaluation\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**4. Stage 4: Closing the feedback loop:** \n",
    "   \n",
    "   4.1. Improving the assistant using the interactive learning\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "      \n",
    "**5. Stage 5: Integrating the chatbot with Slack:**  \n",
    "   \n",
    "   5.1. Setup the credentials   \n",
    "    5.2. Ngrok for local testing    \n",
    "    5.3. Start the rasa core server \n",
    "    \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcjuA1LQY8gD"
   },
   "source": [
    "## 0. Intro\n",
    "In this section, we will install all the necessary dependencies needed to successfully run this exercise.\n",
    "### 0.1. Setup and installation\n",
    "The best way to insall the necessary modules is to use the requirements.txt file. After creating a virtual environment, run:\n",
    "\n",
    "**pip install -r requirements.txt**\n",
    "\n",
    "Throughout this workshop, we will use only open source tools. The code block below checks if Rasa NLU and Rasa Core have been installed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"\n",
    "rasa[spacy]\n",
    "git+https://github.com/apixu/apixu-python.git\n",
    "ngrok\n",
    "\"\"\"\n",
    "%store requirements > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa.nlu\n",
    "import rasa.core\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa.nlu.__version__, rasa.core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also download **Spacy's English language model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy link en_core_web_md en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the working directory** to a newly created one where the necessary project files should be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create **a new Rasa project**. To do this, run:\n",
    "\n",
    "**rasa init --no-prompt**\n",
    "\n",
    "The **rasa init** command creates all the files that a Rasa project needs and trains a simple bot on some sample data. If you leave out the **--no-prompt** flag you will be asked some questions about how you want your project to be set up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rasa init --no-prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otiy7w8KY8gO"
   },
   "source": [
    "## 1. Natural Language Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ln7WpHz_Y8gQ"
   },
   "source": [
    "In this section, you will enable your assistant to understand the user inputs by building a Rasa NLU model. This model will take unstructured user inputs and extract structured data in a form of intents and entities:  \n",
    "- *intent* - a label which represents the overall intention of the user 's input\n",
    "- *entity* - important detail which an assistant should extract and use to steer the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGmj13eJY8gS"
   },
   "source": [
    "### 1.1. Designing a happy path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lomSlZJJY8gU"
   },
   "source": [
    "A good starting point is to define a happy path first. A happy path is a conversation flow where the user provides all the required information and allows the assistant to lead the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLHAPQJHY8gX"
   },
   "source": [
    "### 1.2. Designing the NLU training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMvZPh_XY8gY"
   },
   "source": [
    "To train the NLU model you will need some labeled training data. Rasa NLU training data samples consist of the following components:  \n",
    "- intent label which starts with a prefix *\n",
    "- examples of text inputs which correspond to that label\n",
    "- entities which follow the format *[entity_value] (entity_label)*\n",
    "\n",
    "We will start by generating some training data examples by hand. For a completed data file check out the *helper_files/nlu_data.md* in the repository of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8c9n_YTxY8ga",
    "outputId": "e4f7d9c7-7c26-4963-88d5-fdc670ad6811"
   },
   "outputs": [],
   "source": [
    "%%writefile data/nlu.md\n",
    "## intent:greet\n",
    "- Hello\n",
    "- hey\n",
    "- hello\n",
    "- heya\n",
    "- howdy\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see ya\n",
    "- see you later\n",
    "\n",
    "## intent:inform\n",
    "- What's the weather today?\n",
    "- What's the weather in [London](location) today?\n",
    "- Show me what's the weather in [Paris](location)\n",
    "- I wonder what is the weather in [Vilnius](location) right now?\n",
    "- what is the weather?\n",
    "- Tell me the weather\n",
    "- Is the weather nice in [Barcelona](location) today?\n",
    "- I am going to [London](location) today and I wonder what is the weather out there?\n",
    "- I am planning my trip to [Amsterdam](location). What is the weather out there?\n",
    "- Show me the weather in [Dublin](location), please\n",
    "- in [London](location)\n",
    "- [Lithuania](location)\n",
    "- Oh, sorry, in [Italy](location)\n",
    "- Tell me the weather in [Vilnius](location)\n",
    "- The weather condition in [Italy](location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgzzQuO_Y8ge"
   },
   "source": [
    "\n",
    "## 1.3 Designing the training pipeline\n",
    "\n",
    "Once the training data is ready, we can define the NLU model. We can do that by constructing the processing pipeline which defines how structured data will be extracted from unstructured user inputs: how the sentences will be tokenized, what intent classifier will be used, what entity extraction model will be used, etc. Each component in a training pipeline is trained one after another and can take inputs from the previously defined component as well as pass some information to subsequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjJNLeWgY8gf"
   },
   "outputs": [],
   "source": [
    "%%writefile config.yml\n",
    "# Configuration for Rasa NLU.\n",
    "# https://rasa.com/docs/rasa/nlu/components/\n",
    "language: \"en\"\n",
    "#pipeline: \"pretrained_embeddings_spacy\"\n",
    "pipeline:\n",
    "- name: \"SpacyNLP\"                    # loads the spacy language model\n",
    "- name: \"SpacyTokenizer\"              # splits the sentence into tokens\n",
    "- name: \"SpacyFeaturizer\"             # transform the sentence into a vector representation\n",
    "- name: \"RegexFeaturizer\"\n",
    "- name: \"CRFEntityExtractor\"\n",
    "- name: \"EntitySynonymMapper\"         # trains the synonyms\n",
    "- name: \"SklearnIntentClassifier\"     # uses the vector representation to classify using SVM\n",
    "\n",
    "# Configuration for Rasa Core.\n",
    "# https://rasa.com/docs/rasa/core/policies/\n",
    "policies:\n",
    "  - name: MemoizationPolicy\n",
    "  - name: KerasPolicy\n",
    "  - name: MappingPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c58NdY_RY8h1"
   },
   "source": [
    "# 2. Dialogue Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyEqBxGVY8h2"
   },
   "source": [
    "In this section of this workshop you will build a machine learning-based dialogue model which will enable your assistant to decide on how to respond to user inputs based on the state of the conversation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyAMbLsJY8h3"
   },
   "source": [
    "## 2.1 Designing the training stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPqNmWcTY8h4"
   },
   "source": [
    "Let's start with generating the training data. Rasa Core models learn by observing real conversational data between the user and the assistant. The only important thing is that this data has to be converted into the Rasa Core format: user inputs have to be expressed as corresponding intents (and entities where necessary) while the responses of the assistant are expressed as action names. Each training story follows the format:  \n",
    "- the story starts with a story name which has a prefix ##  \n",
    "- intents, corresponding to user inputs, start with *  \n",
    "- if NLU model extracts entities which should influence the predictions of the dialogue model, they have to be included in the stories using the following format: * intent{'entity_name':\"entity_value\"}  \n",
    "- the responses of the bot start with -  \n",
    "- the story ends with an empty line which marks the end of the story\n",
    "\n",
    "In the next step of this tutorial, we will generate some training stories to cover the happy path. To see a complete training data example, check out the **data/stories.md** file of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hDbP8XPY8h5"
   },
   "outputs": [],
   "source": [
    "%%writefile data/stories.md\n",
    "## Generated Story 3320800183399695936\n",
    "* greet\n",
    "    - utter_greet\n",
    "* inform\n",
    "    - utter_ask_location\n",
    "* inform{\"location\": \"italy\"}\n",
    "    - slot{\"location\": \"italy\"}\n",
    "    - action_weather\n",
    "    - slot{\"location\": \"italy\"}\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - export\n",
    "## Generated Story -3351152636827275381\n",
    "* greet\n",
    "    - utter_greet\n",
    "* inform{\"location\": \"London\"}\n",
    "    - slot{\"location\": \"London\"}\n",
    "    - action_weather\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - export\n",
    "## Generated Story 8921121480760034253\n",
    "* greet\n",
    "    - utter_greet\n",
    "* inform\n",
    "    - utter_ask_location\n",
    "* inform{\"location\":\"London\"}\n",
    "    - slot{\"location\": \"London\"}\n",
    "    - action_weather\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - export\n",
    "## Generated Story -5208991511085841103\n",
    "    - slot{\"location\": \"London\"}\n",
    "    - action_weather\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - export\n",
    "## Generated Story -5208991511085841103\n",
    "    - slot{\"location\": \"London\"}\n",
    "    - action_weather\n",
    "* goodbye\n",
    "    - utter_goodbye\n",
    "    - export\n",
    "## story_001\n",
    "* greet\n",
    "   - utter_greet\n",
    "* inform\n",
    "   - utter_ask_location\n",
    "* inform{\"location\":\"London\"}\n",
    "   - slot{\"location\": \"London\"}\n",
    "   - action_weather\n",
    "* goodbye\n",
    "   - utter_goodbye\n",
    "## story_002\n",
    "* greet\n",
    "   - utter_greet\n",
    "* inform{\"location\":\"Paris\"}\n",
    "   - slot{\"location\": \"Paris\"}\n",
    "   - action_weather\n",
    "* goodbye\n",
    "   - utter_goodbye \n",
    "## story_003\n",
    "* greet\n",
    "   - utter_greet\n",
    "* inform\n",
    "   - utter_ask_location\n",
    "* inform{\"location\":\"Vilnius\"}\n",
    "   - slot{\"location\": \"Vilnius\"}\n",
    "   - action_weather\n",
    "* goodbye\n",
    "   - utter_goodbye\n",
    "## story_004\n",
    "* greet\n",
    "   - utter_greet\n",
    "* inform{\"location\":\"Italy\"}\n",
    "   - slot{\"location\": \"Italy\"}\n",
    "   - action_weather\n",
    "* goodbye\n",
    "   - utter_goodbye \n",
    "## story_005\n",
    "* greet\n",
    "   - utter_greet\n",
    "* inform\n",
    "   - utter_ask_location\n",
    "* inform{\"location\":\"Lithuania\"}\n",
    "   - slot{\"location\": \"Lithuania\"}\n",
    "   - action_weather\n",
    "* goodbye\n",
    "   - utter_goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_d7jkssY8iB"
   },
   "source": [
    "### 2.2 Creating custom action\n",
    "\n",
    "We are going to use the backend integration to enable our assistant to fetch the relevant data based on user's queries. For that, we will create custom actions which, when predicted, will collect necessary data and use it to steer the conversation further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbUx1oTNY8iD"
   },
   "outputs": [],
   "source": [
    "%%writefile actions.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from rasa_sdk import Action\n",
    "from rasa_sdk.events import SlotSet\n",
    "\n",
    "class ActionWeather(Action):\n",
    "\tdef name(self):\n",
    "\t\treturn 'action_weather'\n",
    "\t\t\n",
    "\tdef run(self, dispatcher, tracker, domain):\n",
    "\t\tfrom apixu.client import ApixuClient\n",
    "\t\tapi_key = '' #your apixu key\n",
    "\t\tclient = ApixuClient(api_key)\n",
    "\t\t\n",
    "\t\tloc = tracker.get_slot('location')\n",
    "\t\tcurrent = client.getcurrent(q=loc)\n",
    "\t\t\n",
    "\t\tcountry = current['location']['country']\n",
    "\t\tcity = current['location']['name']\n",
    "\t\tcondition = current['current']['condition']['text']\n",
    "\t\ttemperature_c = current['current']['temp_c']\n",
    "\t\thumidity = current['current']['humidity']\n",
    "\t\twind_mph = current['current']['wind_mph']\n",
    "\n",
    "\t\tresponse = \"\"\"It is currently {} in {} at the moment. The temperature is {} degrees, the humidity is {}% and the wind speed is {} mph.\"\"\".format(condition, city, temperature_c, humidity, wind_mph)\n",
    "\t\t\t\t\t\t\n",
    "\t\tdispatcher.utter_message(response)\n",
    "\t\treturn [SlotSet('location',loc)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUAojX1CY8iH"
   },
   "source": [
    "## 2.3 Defining the domain\n",
    "\n",
    "Once we have the training data in place, we can define the domain of our assistant. A domain defines the environment in which the assistant operates - what user inputs it should expect to see, what actions it should be able to predict, what information the assistant should store throughout the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0yAXKlIY8iI"
   },
   "outputs": [],
   "source": [
    "%%writefile domain.yml\n",
    "slots:\n",
    "  location:\n",
    "    type: text\n",
    "\n",
    "\n",
    "intents:\n",
    " - greet\n",
    " - goodbye\n",
    " - inform\n",
    "\n",
    "\n",
    "entities:\n",
    " - location\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "    - text: 'Hello! How can I help?'\n",
    "  utter_goodbye:\n",
    "    - text: 'Talk to you later.'\n",
    "    - text: 'Bye bye :('\n",
    "  utter_ask_location:\n",
    "    - text: 'In what location?'\n",
    "\n",
    "\n",
    "actions:\n",
    " - utter_greet\n",
    " - utter_goodbye\n",
    " - utter_ask_location\n",
    " - action_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEyD-aF5Y8iL"
   },
   "source": [
    "## 3. Training and testing the model\n",
    "\n",
    "We now have all the components necessary to train our first model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Training the bot\n",
    "\n",
    "The code cell below will train the model using the defined pipeline and policies and store the model in a specified location for us to test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TaMe2n1Y8iY"
   },
   "outputs": [],
   "source": [
    "!rasa train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Testing the bot in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before testing the bot, first we need to start our **action server** in **a new terminal**. Following command will start the action server.\n",
    "\n",
    "**rasa run actions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to add the endpoint file to setup the connection between the action server and the rasa core server.\n",
    "\n",
    "**endpoints.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile endpoints.yml\n",
    "action_endpoint:\n",
    "  url: \"http://localhost:5055/webhook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following script will loads your trained model and lets you talk to your assistant on the command line **(You may need to run this in a new terminal)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rasa shell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6fnBNS_Y8i6"
   },
   "source": [
    "## 3.3. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rkP0XmvY8i7"
   },
   "source": [
    "Another great way to see how good our model is, is to test it using evaluation script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gs6H4epKY8i8"
   },
   "outputs": [],
   "source": [
    "!rasa test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rkP0XmvY8i7"
   },
   "source": [
    "You can visualize your training stories using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gs6H4epKY8i8"
   },
   "outputs": [],
   "source": [
    "!rasa visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLBlNGpQY8jA"
   },
   "source": [
    "# 4. Closing the feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6NpsceLY8jB"
   },
   "source": [
    "Developing an assistant is just one part of the process. Another very important part which defines a successful assistant is enabling your assistant to learn from real user feedback. In the last part of this workshop, we will cover two ways to improve your bots using real user feedback - using interactive learning and using the history of the conversations. We will also, connect our assistant to a custom webpage to see how it works in action! We will complete this part using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0OLu2JHY8jC"
   },
   "source": [
    "## 4.1. Improving the assistant using the interactive learning \n",
    "Interactive learning is a great way to improve your assistant and generate more training example by simply talking to your bot and providing feedback for all predictions it made. That is the main idea behind it - instead of responding right away, an assistant will tell you what it thinks it should do next and ask you for feedback. To start the interactive learning session, we will use a command line and use the following command:\n",
    "\n",
    "\n",
    "**rasa interactive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaQbIxnaY8jF"
   },
   "source": [
    "# 5. Integrating the chatbot with Slack "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5F64rDOl90U"
   },
   "source": [
    "In the very last step of this workshop, you will learn how to connect your assistant to slack messaging platform. Rasa already supports many other messaging platforms and also allows you to implement your custom channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5F64rDOl90U"
   },
   "source": [
    "## 5.1. Setup the credentials\n",
    "You need to change **credentials.yml** files as bellow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**credentials.yml**\n",
    "\n",
    "To see the completed file, check out the helper_files/credentials.yml file of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile credentials.yml\n",
    "# This file contains the credentials for the voice & chat platforms\n",
    "# which your bot is using.\n",
    "# https://rasa.com/docs/rasa/user-guide/messaging-and-voice-channels/\n",
    "\n",
    "rest:\n",
    "#  # you don't need to provide anything here - this channel doesn't\n",
    "#  # require any credentials\n",
    "\n",
    "\n",
    "#facebook:\n",
    "#  verify: \"<verify>\"\n",
    "#  secret: \"<your secret>\"\n",
    "#  page-access-token: \"<your page access token>\"\n",
    "\n",
    "slack:\n",
    " slack_token: \"paste your slack token here (xoxb something something)\"\n",
    "#  slack_channel: \"<the slack channel>\"\n",
    "\n",
    "#socketio:\n",
    "#  user_message_evt: <event name for user message>\n",
    "#  bot_message_evt: <event name for but messages>\n",
    "#  session_persistence: <true/false>\n",
    "\n",
    "rasa:\n",
    "  url: \"http://localhost:5002/api\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5F64rDOl90U"
   },
   "source": [
    "## 5.2. Ngrok for local testing\n",
    "Ngrok is a multi-platform tunnelling, reverse proxy software that establishes secure tunnels from a public endpoint such as the internet to a locally running network service. In simple words it means, it opens access to your local app from the internet.\n",
    "\n",
    "You need to start a ngrok in **a new terminal**. Start it by telling it which port we want to expose to the public internet.\n",
    "\n",
    "**ngrok http 5005**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Start the rasa core server \n",
    "After setting up the backend, we will start our assistant on a server and connect to the UI using:\n",
    "\n",
    "**rasa run --endpoints endpoints.yml**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GEyD-aF5Y8iL",
    "c0OLu2JHY8jC"
   ],
   "name": "Copy of Icter19_chatbotworkshop.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
